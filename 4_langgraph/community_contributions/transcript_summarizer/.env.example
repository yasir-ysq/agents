# Environment Configuration
OLLAMA_BASE_URL=http://localhost:11434
GRADIO_PORT=7860
MAX_CONCURRENT_REQUESTS=3
REQUEST_TIMEOUT=300

# Logging Configuration
# LOG_LEVEL can be: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO
LLM_PROVIDER="gemini"

# Model Configuration
GEMINI_MODEL_NAME=gemini-2.5-flash
GEMINI_API_KEY=""
OLLAMA_MODEL_NAME=llama3
CHUNK_SIZE=2000
CHUNK_OVERLAP=200
TEMPERATURE=0.3